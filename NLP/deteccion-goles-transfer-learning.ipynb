{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimación de estadísticas a partir de un *corpus*\n",
    "\n",
    "A partir de la narración de un partido de futbol, tomamos diferentes enfoques de **Natural Language Processing** y técnicas de *machine learning* para obtener la cantidad de goles que se dieron en el partido. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link del partido\n",
    "El script del partido utilizado es del siguiente enlace:\n",
    "\n",
    "https://youtu.be/YV1eb5-JPrw\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación de las frases que correspondieron a un gol\n",
    "Para los modelos presentados más adelante, tenemos las frases de los comentaristas y definimos un vector con 1's en las posiciones donde ocurrieron goles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Número de oraciones (ejemplos):  22\n"
    }
   ],
   "source": [
    "# Ocurrencias de palabra \"goal\" +- 20 palabras atrás y adelante\n",
    "docs = [\"this locker room with this score lane the threat that his team have produced [music] still looking for the go-ahead goal but it defended as well as he could against the barcelona team that isn't doing too much wrong could\",\n",
    " 'come back he will tonight in his dreams now keeping a few numbers back do not want to surrender a goal before the break if they can avoid it what a sonido got the ball and neymar needed to get',\n",
    " \"be the goat as plenty of superstars out there to make the difference i think there's going to be a goal or two in this second novel but real madrid who's got the bench it could perhaps make a difference\",\n",
    " 'ricky by [applause] do not actually scored in his first two classic rows andreessen rica followed up of a game-tying goal the next year only on the warriors today i send a change between nes that and messi been going',\n",
    " \"just can't find enough rainbow on that pass to take it over the top of marcel winter capisce the breakthrough goal coming from the beheaded boy niki sanders would we're back his little boy and shakira it's a wonderful hello\",\n",
    " 'even for the costa rica man the greatest gear for the greatest game in the world at soccer calm second goal of the season for pk raqqa ditch puts it in perfectly here i said there was a golden ray',\n",
    " \"in recent years not quite back to his sevilla days we'll pass it off this time gets messy with the goal barcelona be a bit more patient not steal against roma is not the only derby of note the classical\",\n",
    " \"upstairs wanted to see a little bit more magic from this classical encounter knotted up at one won't see a goal for 56 minutes we see two and seven who is never satisfied that's for sure sounding like a man\",\n",
    " 'air set the table for kareem and the cream rises to the top again inside for iniesta when he first goal for ben zoma tying his watermark in spain still in the race for the pichichi all those looks away',\n",
    " 'juan carlos moon zuy he steps up in place of luis enrique for every set play a free-kick around the goal and also a corner that was not an accident that was purposely by design neymar came across and when',\n",
    " 'accident that was purposely by design neymar came across and when all the players were celebrating after bk scored the goal javier mascherano ran across to warn carlos and zuy and congratulated him back to you phil on the defensive',\n",
    " 'benzema the player coming out a different look they see different animal the content here to place been fitting wonderful goal scorer for real madrid he brought them back into this game gets the caned i trace from the world-class',\n",
    " 'chance for anybody once it got over and took that deflection but he catapulted that one horn when he first goal of the season in league play for benzema now this will likely push ronaldo higher up more into that',\n",
    " 'earns the whistle real question now is for real madrid how much do they want to push for a second goal as barcelona looks content to bleed another game off the schedule as he stripped conseguido again si out whines',\n",
    " \"feeds i don't see anything wrong there people i'm sorry on that angle there's nothing wrong that's a legitimately grid goal by gareth from this angle and again that's a very harsh call against the mayor breathing dragon that rises\",\n",
    " 'zinedine zidane he has come to life in the second half here on the bench for real madrid when the goal went in he celebrated with his technical staff with the substitute with everybody and he seemed to be the',\n",
    " 'with the substitute with everybody and he seemed to be the last person inside camp now that realized that the goal was disallowed it was phenomenal viewing see dan clearly furious afterwards phil thank you very much ter daughter sobrino',\n",
    " \"attempt at defending from alba and gareth again so close to not making lo do bravo and getting the go-ahead goal yet again there will be plenty to argue about back in the nation's capital oh ramos going in strong\",\n",
    " 'always categorizes not perhaps getting along with each other only got along each other lake heckle and jeckle their wonderful goal for the lead 7th minute is neymar bursting forward looking for an equaliser top of the box lays it',\n",
    " 'back messi the flex kicked off by any and cleared we still might have some change but what a huge goal for ronaldo only the eight league clásico goal he is scored but the 16th of all time only disgusting',\n",
    " 'and cleared we still might have some change but what a huge goal for ronaldo only the eight league clásico goal he is scored but the 16th of all time only disgusting chance for swat has been a push and',\n",
    " \"of it now it seems as though barcelona with a spark they've got a man advantage but they're down a goal and two minutes left of regulation did they take it too easy the 39 match unbeaten streak about to\"]\n",
    "\n",
    "print('Número de oraciones (ejemplos): ', len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [1.],\n       [1.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [1.]])"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# Definimos las oraciones en donde hubo gol\n",
    "labels = np.zeros(22)\n",
    "labels[[8, 9, 21]] = 1.\n",
    "labels.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Modelo de redes neuronales recurrentes (RNN) con GloVe *embeddings*\n",
    "\n",
    "A continuación, planteamos un modelo de redes neuronales recurrentes para aprender la ocurrencia de oraciones (secuencias) que indican mayor probabilidad de gol.  \n",
    " \n",
    "### *Transfer learning* con GloVe\n",
    "Para esto, utilizamos un *embedding* preentrenado de Glove (https://nlp.stanford.edu/projects/glove/). Específicamente, el archivo de *embedding* de Twitter de 25 dimensiones para las palabras, debido a que en este se registran cercanías semánticas con algunos de los jugadores de futbol en el script.\n",
    "\n",
    "### LSTM con keras\n",
    "Aplicamos un modelo de redes neuronales recurrentes con keras para aprender las secuencias con mayor probabilidad de gol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Flatten, Embedding\n",
    "from tensorflow.keras.initializers import Constant\n",
    "\n",
    "import tensorflow as tf\n",
    "gpu = tf.config.experimental.list_physical_devices('GPU')[0]\n",
    "tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiciones útiles\n",
    "MAX_SEQUENCE_LENGTH = 45\n",
    "EMBEDDING_DIM = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Tamaño del vocabulario: 394\n"
    }
   ],
   "source": [
    "# Preparar el Tokenizer\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(docs)\n",
    "# Obtener las secuencias de números\n",
    "sequences = t.texts_to_sequences(docs)\n",
    "\n",
    "# Vocabulario y tamaño del vocabulario\n",
    "word_index = t.word_index\n",
    "vocab_size = len(word_index) + 1\n",
    "print(\"Tamaño del vocabulario: %d\" % (vocab_size))\n",
    "\n",
    "# Obtener las secuencias espaciadas (o uniformes)\n",
    "data = sequence.pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH, padding=\"pre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([  0,   0,   0,   0,   0,  11,  10,  24,  10, 379,  19, 380,  34,\n        12,   2, 381, 382,  25,   2,  60, 383,  14, 384, 385,   2,   3,\n         5,  39, 101, 386,  11, 387, 388,  36,  89,  10,  76, 389,   1,\n       390, 391, 392, 393, 130,   6])"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# Secuencia correspondiente a la oración 21\n",
    "data[21, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Índice de palabras para entrenar el modelo\n",
    "# word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar el *embedding* a la memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cargar el modelo Stanford Glove de Twitter\n",
    "word2vec_file = '../../Glove/glove.twitter.27B.25d.word2vec'\n",
    "glove_model = KeyedVectors.load_word2vec_format(word2vec_file, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([-0.77069  ,  0.12827  ,  0.33137  ,  0.0050893, -0.47605  ,\n       -0.50116  ,  1.858    ,  1.0624   , -0.56511  ,  0.13328  ,\n       -0.41918  , -0.14195  , -2.8555   , -0.57131  , -0.13418  ,\n       -0.44922  ,  0.48591  , -0.6479   , -0.84238  ,  0.61669  ,\n       -0.19824  , -0.57967  , -0.65885  ,  0.43928  , -0.50473  ],\n      dtype=float32)"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "# Embedding de la palabra hello\n",
    "glove_model['hello']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('iniesta', 0.9716404676437378),\n ('messi', 0.9683734178543091),\n ('xavi', 0.9600971341133118),\n ('casillas', 0.9525176882743835),\n ('falcao', 0.945814847946167)]"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "# Palabras más cercanas a Cristiano Ronaldo\n",
    "glove_model.most_similar(positive=[\"cristiano\"], topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('paraguay', 0.958189845085144),\n ('ecuador', 0.9491326808929443),\n ('bolivia', 0.9409966468811035),\n ('nicaragua', 0.940276026725769),\n ('honduras', 0.9361501336097717)]"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "# Palabras más cercanas a la palabra \"goal\"\n",
    "glove_model.most_similar(positive=[\"guatemala\"], topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "La llave no está definida\n"
    }
   ],
   "source": [
    "try: \n",
    "    print(glove_model['NO'])\n",
    "except KeyError: \n",
    "    print(\"La llave no está definida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicación de la técnica de *Transfer learning*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una matriz de embedding para el vocabulario\n",
    "embedding_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    try:\n",
    "        embedding_vector = glove_model[word]\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    except KeyError:\n",
    "        # Las palabras no encontradas en el modelo glove serán cero\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(394, 25)"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar la matriz de embedding en una capa de Embedding\n",
    "# Configuramos trainable = False para mantener el embedding fijo\n",
    "embedding_layer = Embedding(vocab_size, EMBEDDING_DIM,\n",
    "                            embeddings_initializer=Constant(embedding_matrix),\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.layers.embeddings.Embedding at 0x1c13a63fac8>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "embedding_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta capa se define como no entrenable debido a que ya contiene embebida los vectores de ponderaciones para las secuencias del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definir el modelo RNN con keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        (None, 45, 25)            9850      \n_________________________________________________________________\nlstm (LSTM)                  (None, 10)                1440      \n_________________________________________________________________\ndense (Dense)                (None, 1)                 11        \n=================================================================\nTotal params: 11,301\nTrainable params: 1,451\nNon-trainable params: 9,850\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "# Definir el modelo secuencial\n",
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.add(LSTM(10))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# Resumir el modelo\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 22 samples\nEpoch 1/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.2112 - accuracy: 0.8636\nEpoch 2/100\n22/22 [==============================] - 0s 909us/sample - loss: 0.2079 - accuracy: 0.8636\nEpoch 3/100\n22/22 [==============================] - 0s 868us/sample - loss: 0.2046 - accuracy: 0.8636\nEpoch 4/100\n22/22 [==============================] - 0s 828us/sample - loss: 0.2013 - accuracy: 0.8636\nEpoch 5/100\n22/22 [==============================] - 0s 867us/sample - loss: 0.1980 - accuracy: 0.8636\nEpoch 6/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.1947 - accuracy: 0.8636\nEpoch 7/100\n22/22 [==============================] - 0s 909us/sample - loss: 0.1913 - accuracy: 0.8636\nEpoch 8/100\n22/22 [==============================] - 0s 888us/sample - loss: 0.1880 - accuracy: 0.8636\nEpoch 9/100\n22/22 [==============================] - 0s 908us/sample - loss: 0.1847 - accuracy: 0.9091\nEpoch 10/100\n22/22 [==============================] - 0s 911us/sample - loss: 0.1814 - accuracy: 0.9091\nEpoch 11/100\n22/22 [==============================] - 0s 997us/sample - loss: 0.1781 - accuracy: 0.9091\nEpoch 12/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.1749 - accuracy: 0.9091\nEpoch 13/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.1718 - accuracy: 0.9091\nEpoch 14/100\n22/22 [==============================] - 0s 997us/sample - loss: 0.1687 - accuracy: 0.9091\nEpoch 15/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.1656 - accuracy: 0.9091\nEpoch 16/100\n22/22 [==============================] - 0s 958us/sample - loss: 0.1626 - accuracy: 0.9091\nEpoch 17/100\n22/22 [==============================] - 0s 997us/sample - loss: 0.1597 - accuracy: 0.9091\nEpoch 18/100\n22/22 [==============================] - 0s 997us/sample - loss: 0.1568 - accuracy: 0.9091\nEpoch 19/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.1540 - accuracy: 0.9091\nEpoch 20/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.1513 - accuracy: 0.9091\nEpoch 21/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.1486 - accuracy: 0.9091\nEpoch 22/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.1459 - accuracy: 0.9091\nEpoch 23/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.1433 - accuracy: 0.9545\nEpoch 24/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.1408 - accuracy: 0.9545\nEpoch 25/100\n22/22 [==============================] - 0s 999us/sample - loss: 0.1383 - accuracy: 0.9545\nEpoch 26/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.1358 - accuracy: 0.9545\nEpoch 27/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.1334 - accuracy: 0.9545\nEpoch 28/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.1311 - accuracy: 0.9545\nEpoch 29/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.1287 - accuracy: 1.0000\nEpoch 30/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.1265 - accuracy: 1.0000\nEpoch 31/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.1243 - accuracy: 1.0000\nEpoch 32/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.1221 - accuracy: 1.0000\nEpoch 33/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.1200 - accuracy: 1.0000\nEpoch 34/100\n22/22 [==============================] - 0s 934us/sample - loss: 0.1180 - accuracy: 1.0000\nEpoch 35/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.1159 - accuracy: 1.0000\nEpoch 36/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.1140 - accuracy: 1.0000\nEpoch 37/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.1120 - accuracy: 1.0000\nEpoch 38/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.1101 - accuracy: 1.0000\nEpoch 39/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.1083 - accuracy: 1.0000\nEpoch 40/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.1065 - accuracy: 1.0000\nEpoch 41/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.1047 - accuracy: 1.0000\nEpoch 42/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.1030 - accuracy: 1.0000\nEpoch 43/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.1013 - accuracy: 1.0000\nEpoch 44/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.0997 - accuracy: 1.0000\nEpoch 45/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.0980 - accuracy: 1.0000\nEpoch 46/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.0964 - accuracy: 1.0000\nEpoch 47/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.0949 - accuracy: 1.0000\nEpoch 48/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.0933 - accuracy: 1.0000\nEpoch 49/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.0919 - accuracy: 1.0000\nEpoch 50/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.0904 - accuracy: 1.0000\nEpoch 51/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.0889 - accuracy: 1.0000\nEpoch 52/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.0875 - accuracy: 1.0000\nEpoch 53/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.0862 - accuracy: 1.0000\nEpoch 54/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.0848 - accuracy: 1.0000\nEpoch 55/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.0835 - accuracy: 1.0000\nEpoch 56/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.0822 - accuracy: 1.0000\nEpoch 57/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.0809 - accuracy: 1.0000\nEpoch 58/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.0797 - accuracy: 1.0000\nEpoch 59/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.0784 - accuracy: 1.0000\nEpoch 60/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.0772 - accuracy: 1.0000\nEpoch 61/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.0761 - accuracy: 1.0000\nEpoch 62/100\n22/22 [==============================] - 0s 925us/sample - loss: 0.0749 - accuracy: 1.0000\nEpoch 63/100\n22/22 [==============================] - 0s 856us/sample - loss: 0.0738 - accuracy: 1.0000\nEpoch 64/100\n22/22 [==============================] - 0s 816us/sample - loss: 0.0727 - accuracy: 1.0000\nEpoch 65/100\n22/22 [==============================] - 0s 896us/sample - loss: 0.0716 - accuracy: 1.0000\nEpoch 66/100\n22/22 [==============================] - 0s 868us/sample - loss: 0.0706 - accuracy: 1.0000\nEpoch 67/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.0696 - accuracy: 1.0000\nEpoch 68/100\n22/22 [==============================] - 0s 817us/sample - loss: 0.0685 - accuracy: 1.0000\nEpoch 69/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.0676 - accuracy: 1.0000\nEpoch 70/100\n22/22 [==============================] - 0s 954us/sample - loss: 0.0666 - accuracy: 1.0000\nEpoch 71/100\n22/22 [==============================] - 0s 991us/sample - loss: 0.0657 - accuracy: 1.0000\nEpoch 72/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.0648 - accuracy: 1.0000\nEpoch 73/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.0639 - accuracy: 1.0000\nEpoch 74/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.0630 - accuracy: 1.0000\nEpoch 75/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.0621 - accuracy: 1.0000\nEpoch 76/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.0613 - accuracy: 1.0000\nEpoch 77/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.0605 - accuracy: 1.0000\nEpoch 78/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.0597 - accuracy: 1.0000\nEpoch 79/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.0589 - accuracy: 1.0000\nEpoch 80/100\n22/22 [==============================] - 0s 962us/sample - loss: 0.0581 - accuracy: 1.0000\nEpoch 81/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.0574 - accuracy: 1.0000\nEpoch 82/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.0566 - accuracy: 1.0000\nEpoch 83/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.0559 - accuracy: 1.0000\nEpoch 84/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.0552 - accuracy: 1.0000\nEpoch 85/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.0545 - accuracy: 1.0000\nEpoch 86/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.0539 - accuracy: 1.0000\nEpoch 87/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.0532 - accuracy: 1.0000\nEpoch 88/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.0526 - accuracy: 1.0000\nEpoch 89/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.0519 - accuracy: 1.0000\nEpoch 90/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.0513 - accuracy: 1.0000\nEpoch 91/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.0507 - accuracy: 1.0000\nEpoch 92/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.0501 - accuracy: 1.0000\nEpoch 93/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.0496 - accuracy: 1.0000\nEpoch 94/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.0490 - accuracy: 1.0000\nEpoch 95/100\n22/22 [==============================] - 0s 952us/sample - loss: 0.0484 - accuracy: 1.0000\nEpoch 96/100\n22/22 [==============================] - 0s 997us/sample - loss: 0.0479 - accuracy: 1.0000\nEpoch 97/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.0473 - accuracy: 1.0000\nEpoch 98/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.0468 - accuracy: 1.0000\nEpoch 99/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.0463 - accuracy: 1.0000\nEpoch 100/100\n22/22 [==============================] - 0s 1ms/sample - loss: 0.0458 - accuracy: 1.0000\n"
    }
   ],
   "source": [
    "# Ajustar el modelo\n",
    "#model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3, batch_size=64)\n",
    "history = model.fit(data, labels, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[0.02021797, 0.        ],\n       [0.01971275, 0.        ],\n       [0.02188036, 0.        ],\n       [0.02423301, 0.        ],\n       [0.02097651, 0.        ],\n       [0.02472274, 0.        ],\n       [0.02494118, 0.        ],\n       [0.01752526, 0.        ],\n       [0.86930841, 1.        ],\n       [0.82751679, 1.        ],\n       [0.02429537, 0.        ],\n       [0.01819284, 0.        ],\n       [0.02426372, 0.        ],\n       [0.02509282, 0.        ],\n       [0.0235166 , 0.        ],\n       [0.01813381, 0.        ],\n       [0.02105876, 0.        ],\n       [0.02858564, 0.        ],\n       [0.03306217, 0.        ],\n       [0.01912416, 0.        ],\n       [0.02335004, 0.        ],\n       [0.79572475, 1.        ]])"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "# Comparación de los datos ajustados por el modelo y los observados\n",
    "np.column_stack((model.predict(data) , labels.reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[0.02021797]], dtype=float32)"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "# Para predecir un único valor\n",
    "model.predict(data[0].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Se ha guardado el modelo y sus parámetros\n"
    }
   ],
   "source": [
    "# Serializar el modelo a formato JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"nlp-football-model-lstm.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "# Escribir los pesos sinápticos en formato HDF5\n",
    "model.save_weights(\"nlp-football-model-lstm-weights.h5\")\n",
    "print(\"Se ha guardado el modelo y sus parámetros\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar el modelo entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Modelo cargado del disco\n"
    }
   ],
   "source": [
    "# Cargar el arcihvo json y crear el modelo\n",
    "json_file = open('nlp-football-model-lstm.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "# Crear el modelo\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# Cargar los pesos al modelo\n",
    "loaded_model.load_weights(\"nlp-football-model-lstm-weights.h5\")\n",
    "print(\"Modelo cargado del disco\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[0.02021798]], dtype=float32)"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "loaded_model.predict(data[0].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}