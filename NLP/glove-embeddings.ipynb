{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplo de *embeddings* con `glove`\n",
    "\n",
    "En este cuaderno cargamos modelos de *embeddings* de palabras, preentrenados utilizando bases de datos de tweets y del proyecto [*Spanish Billion Word Corpus*](http://crscardellino.github.io/SBWCE/) (SBWC)\n",
    "\n",
    "Para cargar estos *embeddings* utilizaremos la librería `gensim`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.models import KeyedVectors\n",
    "import gensim\n",
    "gensim.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando el archivo de *embeddings* de Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos el archivo de glove a formato word2Vec\n",
    "glove_input_file = '../../Glove/glove.twitter.27B.200d.txt'\n",
    "word2vec_output_file = '../../Glove/glove.twitter.27B.200d.word2vec'\n",
    "glove2word2vec(glove_input_file, word2vec_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el modelo Stanford Glove\n",
    "word2vec_file = '../../Glove/glove.twitter.27B.200d.word2vec'\n",
    "model = KeyedVectors.load_word2vec_format(word2vec_file, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<gensim.models.keyedvectors.Word2VecKeyedVectors at 0x281fbd20608>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[('queen', 0.6820898056030273)]\n"
    }
   ],
   "source": [
    "# Vamos a calcular un resultado interesante: \n",
    "#   (king - man) + woman = ?\n",
    "exampleResult = model.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)\n",
    "print(exampleResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('bitcoins', 0.6961264610290527),\n ('gox', 0.613304853439331),\n ('currency', 0.5955000519752502),\n ('exchange', 0.5862643718719482),\n ('btc', 0.5816957354545593)]"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "model.most_similar(positive=['bitcoin'], topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('madrid', 0.9010248184204102),\n ('barça', 0.8486793041229248),\n ('barca', 0.8224847316741943),\n ('atletico', 0.7917088270187378),\n ('bayern', 0.791003406047821)]"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "model.most_similar(positive=['barcelona'], topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('ronaldo', 0.8976154327392578),\n ('cristiano', 0.8833505511283875),\n ('lionel', 0.8275080919265747),\n ('iniesta', 0.8245566487312317),\n ('neymar', 0.7740342617034912)]"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "model.most_similar(positive=['messi'], topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('going', 0.8315241932868958),\n ('now', 0.7833804488182068),\n ('out', 0.7351419925689697),\n ('gonna', 0.7180647253990173),\n ('just', 0.715401828289032),\n ('right', 0.711840808391571),\n ('here', 0.7060959339141846),\n ('went', 0.7059710621833801),\n ('still', 0.7032345533370972),\n ('there', 0.7017902135848999)]"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# Conjugación de verbos\n",
    "model.most_similar(positive=['go','playing'],negative=['play'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('caracas', 0.9006860852241516),\n ('bolívar', 0.8420948386192322),\n ('antonio', 0.8349326252937317),\n ('bolivar', 0.831375777721405),\n ('ccs', 0.8311764597892761),\n ('maracaibo', 0.8281850814819336),\n ('valencia', 0.8225287795066833),\n ('pueblo', 0.8219658732414246),\n ('vzla', 0.8169875144958496),\n ('ciudad', 0.8144233226776123)]"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "# Santiago es a Chile, como ? es a Venezuela\n",
    "model.most_similar_cosmul(positive=['santiago','venezuela'],negative=['chile'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'chilli'"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# Encontrar la palabra que no encaja\n",
    "model.doesnt_match(['white','blue','red','chilli'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'september'"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "model.doesnt_match(['monday', 'tuesday', 'september', 'thursday', 'friday'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glove embeddings en español\n",
    "\n",
    "Ahora vamos a mostrar un modelo de *embeddings* entrenado utilizado un corpus principalmente en español. Vea [*Spanish Billion Word Corpus*](http://crscardellino.github.io/SBWCE/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('lana', 0.6366966366767883)]"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "# ¿Qué pasa si utilizamos nuestra analogía en español con los embeddings de Twitter?\n",
    "model.most_similar(positive=['mujer', 'rey'], negative=['hombre'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "spanish_glove_file = '../../Glove/glove-sbwc.i25.vec'\n",
    "model = KeyedVectors.load_word2vec_format(spanish_glove_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('reina', 0.6732202768325806)]"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "model.most_similar(positive=['mujer', 'rey'], negative=['hombre'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('reina', 0.9141066670417786),\n ('isabel', 0.8743277192115784),\n ('princesa', 0.843113124370575),\n ('infanta', 0.8425983190536499),\n ('monarca', 0.8357319831848145),\n ('hija', 0.8211697340011597),\n ('consorte', 0.8179485201835632),\n ('iv', 0.813984215259552),\n ('esposa', 0.8115168213844299),\n ('ii', 0.8099035620689392)]"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "model.most_similar_cosmul(positive=['rey','mujer'],negative=['hombre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('actriz', 0.9732905030250549),\n ('actores', 0.8580312728881836),\n ('actrices', 0.8464058041572571),\n ('cantante', 0.8347789645195007),\n ('reparto', 0.8277631402015686),\n ('protagonista', 0.8202100396156311),\n ('invitada', 0.8101590871810913),\n ('papel', 0.8021049499511719),\n ('guionista', 0.7968517541885376),\n ('intérprete', 0.7961310744285583)]"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "model.most_similar_cosmul(positive=['actor','mujer'],negative=['hombre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('yendo', 0.881558895111084),\n ('llevando', 0.8737362623214722),\n ('ido', 0.8687229156494141),\n ('saliendo', 0.8531793355941772),\n ('seguir', 0.8456405997276306),\n ('haciendo', 0.8450909852981567),\n ('va', 0.8442757725715637),\n ('vaya', 0.838218629360199),\n ('dando', 0.8275400996208191),\n ('estamos', 0.8271223306655884)]"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "model.most_similar_cosmul(positive=['ir','jugando'],negative=['jugar'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'martes'"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "model.doesnt_match(['abril', 'mayo', 'septiembre', 'martes', 'julio'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz de **embeddings** \n",
    "\n",
    "En esta matriz, de dimensiones (tamaño del vocabulario, número de vectores de representación) se encuentran todas las palabras de nuestro modelo de *embeddings*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Dimensiones de la matriz:  (855380, 300)\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[ 0.46591 , -0.306953, -0.121611, ..., -0.519945, -0.181563,\n         0.053406],\n       [ 0.422498, -0.3078  , -0.280862, ..., -0.485321, -0.335308,\n         0.061957],\n       [ 0.476166, -0.530399, -0.346721, ..., -0.221037,  0.328242,\n        -0.029409],\n       ...,\n       [-0.123679,  0.125201,  0.015841, ...,  0.211024,  0.038727,\n         0.017024],\n       [-0.1969  ,  0.060876,  0.277485, ...,  0.090367,  0.034666,\n         0.063083],\n       [-0.137711,  0.071672,  0.077311, ...,  0.206016, -0.009296,\n         0.041523]], dtype=float32)"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "# Embedding matrix\n",
    "print('Dimensiones de la matriz: ', model.wv.syn0.shape)\n",
    "model.wv.syn0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "8218"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "# Buscamos el índice de una de las palabras de nuestro vocabulario\n",
    "model.vocab['messi'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([ 1.129200e-02, -4.461800e-01, -3.060280e-01, -4.500880e-01,\n        5.891050e-01,  3.184560e-01,  1.694610e-01, -2.269950e-01,\n       -2.601360e-01, -6.464100e-01, -2.115800e-01, -4.280970e-01,\n        1.399720e-01, -1.025010e-01,  3.148100e-02,  1.232645e+00,\n        4.914380e-01,  5.427310e-01,  4.458460e-01, -9.787900e-01,\n       -3.448180e-01,  1.122980e-01, -4.260280e-01, -4.002280e-01,\n       -1.101323e+00, -8.437430e-01,  6.715900e-02,  1.781210e-01,\n       -5.808000e-03,  5.459360e-01, -1.001716e+00, -3.673480e-01,\n        4.638800e-01, -3.280870e-01,  2.518610e-01, -2.307630e-01,\n        3.485260e-01,  9.738570e-01, -1.826450e-01, -1.841450e-01,\n        1.695140e-01,  6.740970e-01,  1.978200e-02,  8.347860e-01,\n       -8.490540e-01, -7.982920e-01,  2.854240e-01, -7.705210e-01,\n        1.057605e+00,  1.208000e-02,  3.299240e-01, -9.007300e-02,\n       -7.485000e-03,  5.797900e-02,  4.193790e-01, -4.590200e-02,\n        3.508530e-01, -7.441110e-01,  3.134650e-01, -6.634370e-01,\n       -4.107530e-01, -1.394550e-01, -9.223430e-01, -5.630800e-02,\n       -5.963400e-02, -2.237600e-01, -2.091620e-01,  1.287160e-01,\n       -6.126380e-01, -7.402170e-01,  3.619530e-01, -4.303910e-01,\n       -1.103150e-01,  7.356900e-01,  1.226773e+00, -1.190590e-01,\n        1.524990e-01, -7.263350e-01, -5.782350e-01,  8.457900e-01,\n       -2.168240e-01, -1.724940e-01,  3.038370e-01,  4.817400e-02,\n        5.424950e-01, -1.442520e-01, -1.118137e+00, -5.658200e-02,\n       -4.166960e-01,  2.369030e-01,  7.158350e-01,  9.081670e-01,\n        3.689290e-01,  5.476860e-01, -7.038090e-01, -3.741110e-01,\n       -4.212390e-01,  2.421580e-01,  1.884560e-01,  2.120630e-01,\n       -9.453900e-02,  4.014250e-01, -1.408330e-01, -3.047380e-01,\n       -2.074270e-01, -3.508380e-01,  2.728260e-01, -4.999600e-01,\n       -4.800200e-02, -2.647380e-01,  6.935800e-01, -9.325980e-01,\n       -3.284630e-01, -1.751300e-02,  4.227030e-01,  2.555410e-01,\n       -1.910070e-01, -1.381460e-01, -2.851530e-01,  1.286791e+00,\n       -5.796830e-01, -9.140280e-01, -5.955040e-01, -4.671300e-01,\n        2.833320e-01, -1.962640e-01, -5.465940e-01,  8.680470e-01,\n       -1.551740e-01,  7.343000e-02,  2.165020e-01, -6.946000e-03,\n       -1.342590e-01,  6.992050e-01,  4.020500e-02, -1.582320e-01,\n       -7.967700e-02,  7.107970e-01,  5.614000e-03,  2.195890e-01,\n       -7.717940e-01,  5.088400e-01,  1.944160e-01, -2.160180e-01,\n        3.436810e-01,  4.408650e-01,  5.049990e-01,  8.365340e-01,\n       -1.779010e-01,  2.792800e-02, -8.983030e-01, -2.155840e-01,\n        3.475850e-01,  3.156140e-01,  2.223000e-03,  3.070210e-01,\n        1.727420e-01,  2.642960e-01,  3.608000e-02, -3.011460e-01,\n       -1.686930e-01, -3.645300e-02,  1.349470e-01, -1.072715e+00,\n       -2.794990e-01,  1.586620e-01, -5.011160e-01, -2.440030e-01,\n        4.272800e-01,  1.358660e-01,  6.454650e-01, -8.122200e-02,\n       -2.914000e-03,  2.954200e-01, -4.830130e-01, -3.466690e-01,\n       -3.725780e-01, -5.046700e-02,  2.497190e-01,  3.561050e-01,\n        5.642050e-01,  5.470410e-01, -5.705670e-01,  6.075140e-01,\n       -4.022060e-01, -8.668000e-02, -7.108910e-01,  4.122880e-01,\n        2.058180e-01, -8.338970e-01,  1.810700e-01, -6.612750e-01,\n        8.066540e-01, -3.751790e-01,  1.002420e-01, -9.357900e-02,\n       -1.663900e-02,  4.582430e-01,  6.705450e-01, -8.632390e-01,\n        2.374660e-01, -4.352780e-01,  6.923200e-02, -1.538360e-01,\n        9.743870e-01, -2.967000e-01,  1.687360e-01,  7.604020e-01,\n       -2.586000e-03, -9.958790e-01,  1.317519e+00,  5.051500e-02,\n       -1.361437e+00,  6.542700e-02, -3.969270e-01,  5.066880e-01,\n        1.792550e-01, -3.193760e-01,  1.043210e-01, -6.957600e-02,\n        3.831190e-01,  8.349780e-01, -1.935650e-01, -3.416220e-01,\n       -7.545100e-02, -9.206000e-03,  1.300540e-01, -6.116980e-01,\n        5.400600e-01, -6.178170e-01,  4.144020e-01, -3.795860e-01,\n        4.539630e-01,  5.034850e-01,  5.712700e-02,  3.092950e-01,\n       -4.427460e-01, -7.928520e-01,  9.427400e-01, -3.464480e-01,\n        4.765860e-01, -1.686620e-01,  5.102370e-01, -3.446783e+00,\n        7.138800e-02, -1.558580e-01,  4.295800e-01,  2.064490e-01,\n        2.665800e-02, -7.558700e-02, -3.161710e-01, -1.121553e+00,\n        3.052420e-01,  4.642660e-01,  3.110750e-01,  6.117660e-01,\n       -2.126410e-01,  9.493230e-01,  5.860730e-01,  3.209500e-02,\n       -3.388000e-01,  2.987690e-01,  6.800190e-01,  5.541990e-01,\n       -1.955660e-01, -2.094880e-01, -1.685110e-01, -6.370660e-01,\n       -9.599500e-02, -7.657340e-01,  2.606340e-01,  7.103120e-01,\n       -5.451980e-01,  3.799840e-01,  6.857220e-01,  1.458060e-01,\n       -4.952090e-01, -3.884330e-01,  5.231100e-02,  3.247320e-01,\n       -1.144630e-01,  3.617000e-02,  2.741540e-01,  4.062730e-01,\n       -4.177200e-02, -2.256310e-01, -5.155400e-02, -8.734680e-01,\n        3.500140e-01, -2.775380e-01,  4.299480e-01,  2.192100e-01,\n       -2.972230e-01, -1.158400e-01, -4.203940e-01, -8.510430e-01,\n        2.888160e-01,  9.776600e-01,  1.280371e+00,  3.506900e-02],\n      dtype=float32)"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "# Mostramos su representación 300-dimensional\n",
    "# Señoras y señores, este es 'messi': \n",
    "model.wv.syn0[694]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}